{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 97.57857991903957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['caffeine_calories_predictor_rf.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import joblib\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('archive-4/caffeine.csv')\n",
    "\n",
    "# Convert 'Volume (ml)' and 'Caffeine (mg)' to numeric, handling errors\n",
    "data['Volume (ml)'] = pd.to_numeric(data['Volume (ml)'], errors='coerce')\n",
    "data['Caffeine (mg)'] = pd.to_numeric(data['Caffeine (mg)'], errors='coerce')\n",
    "data['Calories'] = pd.to_numeric(data['Calories'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values\n",
    "data.dropna(subset=['Volume (ml)', 'Caffeine (mg)', 'Calories'], inplace=True)\n",
    "\n",
    "# Features and Target variable\n",
    "X = data[['drink', 'Volume (ml)', 'Caffeine (mg)']]\n",
    "y = data['Calories']\n",
    "\n",
    "# Preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', ['Volume (ml)', 'Caffeine (mg)']),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['drink'])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Creating a pipeline that first transforms the data and then fits a model with RandomForestRegressor\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# Save the model to a pickle file\n",
    "joblib.dump(model, 'caffeine_calories_predictor_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 164.13108182167568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fooditem_calories_predictor.pkl']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from math import sqrt\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('archive-4/calories.csv', delimiter=',')\n",
    "data = pd.read_csv('archive-4/calories.csv', delimiter=',')\n",
    "\n",
    "# Remove 'cal' from 'Cals_per100grams'\n",
    "data['Cals_per100grams'] = data['Cals_per100grams'].str.replace(' cal', '')\n",
    "\n",
    "# Remove 'kJ' from 'KJ_per100grams'\n",
    "data['KJ_per100grams'] = data['KJ_per100grams'].str.replace(' kJ', '')\n",
    "\n",
    "# Remove 'g' from 'per100grams' - assuming you want to convert this to a numeric value as well\n",
    "data['per100grams'] = data['per100grams'].str.replace('g', '')\n",
    "\n",
    "# Convert columns to numeric\n",
    "data['Cals_per100grams'] = pd.to_numeric(data['Cals_per100grams'], errors='coerce')\n",
    "data['KJ_per100grams'] = pd.to_numeric(data['KJ_per100grams'], errors='coerce')\n",
    "data['per100grams'] = pd.to_numeric(data['per100grams'], errors='coerce')\n",
    "\n",
    "\n",
    "# Assuming 'per100grams' is always '100g', so we directly use 'Cals_per100grams' for prediction\n",
    "# Preprocess the data\n",
    "X = data[['FoodItem', 'per100grams']]  # Features - using only FoodItem for simplicity, but you can include more\n",
    "y = data['Cals_per100grams']  # Target variable\n",
    "\n",
    "# Convert 'FoodItem' into numerical format using OneHotEncoder\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'), ['FoodItem']),\n",
    "        ('num', SimpleImputer(strategy='mean'), ['per100grams'])  # Impute missing values with the mean\n",
    "\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a pipeline that first transforms the data and then fits a model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', LinearRegression())])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f'RMSE: {rmse}')\n",
    "joblib.dump(model, 'fooditem_calories_predictor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 92.98479884117609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sujahidbasha/Desktop/DietBuddyResearchProject/backend/venv/lib/python3.12/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fastfood_calories_predictor.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer  # Corrected import statement\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('archive-4/fastfood_calories.csv')\n",
    "\n",
    "# Drop the first unnamed column if it exists\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Assuming 'calories' is the target variable and the rest are features\n",
    "X = data.drop('calories', axis=1)\n",
    "y = data['calories']\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numerical_features = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Preprocessing: OneHotEncode categorical variables and impute missing values\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define the model\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# Save the model to a pickle file\n",
    "joblib.dump(model, 'fastfood_calories_predictor.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below one dont work as i do not have weights distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('archive-4/exercise_dataset.csv')\n",
    "\n",
    "# Transform the dataset to have a row for each weight category\n",
    "melted_data = pd.melt(data, id_vars=['Activity, Exercise or Sport (1 hour)', 'Calories per kg'], \n",
    "                      value_vars=['130 lb', '155 lb', '180 lb', '205 lb'],\n",
    "                      var_name='Weight_Category', value_name='Calories_Burned')\n",
    "\n",
    "# Convert weight category to numeric by extracting the number\n",
    "# melted_data['Weight_Category'] = melted_data['Weight_Category'].str.extract('(\\d+)').astype(int)\n",
    "melted_data['Weight_Category'] = melted_data['Weight_Category'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "# Use 'Calories per kg' as the target for prediction\n",
    "X = melted_data[['Weight_Category', 'Calories_Burned']]  # Features\n",
    "y = melted_data['Activity, Exercise or Sport (1 hour)']  # Target\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "\n",
    "# Creating and Training the model\n",
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'exercise_predictor_model.pkl')\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(sc, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calories_imputer.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('archive-4/Activity_Dataset_V1.csv')\n",
    "\n",
    "# Select only the 'calories' column as feature and 'workout_type' as the target\n",
    "X = data[['calories']]\n",
    "y = data['workout_type']\n",
    "\n",
    "# Handle missing values in 'calories'\n",
    "# Here, we'll impute missing values with the median, but you can choose a strategy that fits your data best\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model and the imputer to pickle files\n",
    "joblib.dump(model, 'calories_based_workout_predictor.pkl')\n",
    "joblib.dump(imputer, 'calories_imputer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cricket: 17.89 minutes at 5.59 calories/minute\n",
      "Outdoor Running: 18.32 minutes at 5.46 calories/minute\n",
      "Outdoor Cycling: 18.86 minutes at 5.30 calories/minute\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Assuming 'data' is your DataFrame with the necessary features and targets\n",
    "X = data[['calories', 'time']]  # Features for classification\n",
    "y_class = data['workout_type']  # Target for classification\n",
    "\n",
    "# Splitting data for classification model\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training classification model\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_class, y_train_class)\n",
    "\n",
    "# For each workout type, train a regressor\n",
    "regressors = {}\n",
    "for workout in y_class.unique():\n",
    "    workout_data = data[data['workout_type'] == workout]\n",
    "    X = workout_data[['calories']]  # Assuming calories is a significant feature for regression\n",
    "    y_reg = workout_data['time']  # Target for regression\n",
    "    \n",
    "    X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.2, random_state=42)\n",
    "    \n",
    "    regressor = RandomForestRegressor()\n",
    "    regressor.fit(X_train_reg, y_train_reg)\n",
    "    regressors[workout] = regressor\n",
    "\n",
    "# Save models\n",
    "joblib.dump(classifier, 'exercise_classifier.pkl')\n",
    "for workout, regressor in regressors.items():\n",
    "    joblib.dump(regressor, f'{workout}_time_regressor.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
